# Epi-Forecasting 시스템 아키텍처 및 로직 심층 분석

## 서문: 이 시스템을 어떻게 이해해야 하는가?

이 시스템을 이해하는 가장 좋은 방법은 **"매우 유능하지만, 모든 것을 숫자로만 생각하는 AI 감염병 분석가"**를 상상하는 것입니다. 이 분석가는 다음과 같은 절차로 일합니다.

1.  **브리핑 받기**: 과거 데이터, 최신 뉴스, 정부 발표 등 모든 정보를 '브리핑 자료'로 전달받습니다.
2.  **전략 수립**: 브리핑 내용을 바탕으로 "이번 유행은 과거 2022년 패턴과 비슷하게 가되, 최근 뉴스를 보니 확산세가 더 빠를 것 같군. 시뮬레이션 강도를 20% 정도 올려보자" 와 같은 '분석 전략'을 수립합니다.
3.  **수천 번의 시뮬레이션**: 수립한 전략에 따라, 앞으로 일어날 수 있는 수천 개의 미래 시나리오를 컴퓨터로 그려봅니다.
4.  **결과 보고**: 수천 개의 시나리오를 종합하여 "가장 가능성 높은 미래(중앙값)는 이것이며, 최악의 경우(상위 95%) 여기까지 갈 수 있습니다" 라고 결론을 내어 보고서를 작성합니다.

이 시스템은 바로 이 전 과정을 자동화한 것입니다. 여기서 **'AI 분석가의 두뇌' 역할을 하는 것이 LLM 에이전트**이며, **'컴퓨터 시뮬레이션'을 수행하는 것이 핵심 예측 알고리즘**입니다.

---

## Part 1: 시스템은 어떻게 생각하고 움직이는가? (실행 흐름)

`rolling_agent_forecast.py` 스크립트를 실행했을 때, 시스템 내부에서 일어나는 일을 시간 순서대로 따라가 보겠습니다.

#### **1단계: 브리핑 준비 (데이터 수집 및 증거팩 생성)**

-   **`adapters.py`**: 먼저 과거의 주간 환자 수 시계열 데이터(`his_outpatient_weekly_epi_counts.csv`)를 불러옵니다. 이것이 가장 기본적인 내부 정보입니다.
-   **`evidence_pack.py`**: '브리핑 자료'인 **증거팩(Evidence Pack)**을 만듭니다.
    -   **`build_evidence_pack_from_gov_monthly_csv`**: 미리 수집된 정부 월간 통계 CSV 파일을 읽습니다. 현재 시점(`as-of`)을 기준으로, 과거 통계만을 사용하여 "최근 4주간 감염병 언급량 변화율" 같은 정량적인 **외부 신호(External Signals)**를 계산합니다.
    -   이 외부 신호와 내부 데이터를 종합하여 하나의 JSON 객체, 즉 증거팩을 완성합니다.

#### **2단계: LLM의 전략 수립 (하이퍼파라미터 제안)**

-   **`agent_loop.py`**: 생성된 증거팩과 직전 예측의 성과(`last_metrics`) 등을 모두 모아 LLM에게 전달할 **관측(Observation)** 객체를 구성합니다.
-   **`llm_agent.py`**: 관측 객체를 받아 시스템 프롬프트와 함께 LLM API를 호출합니다.
    -   **LLM의 역할**: LLM은 증거팩에 담긴 "최근 뉴스 신호가 강하다"는 정보와 "직전 예측의 커버리지가 너무 낮았다"는 성과 정보를 보고, 이번 시뮬레이션에 사용할 최적의 **'전략'(=하이퍼파라미터 세트)**을 JSON 형태로 제안합니다. 예를 들어, 다음과 같이 생각합니다.
        > "뉴스 신호가 강하니 `news_signal` 값을 0.6으로 높이고, 지난번 예측 밴드가 너무 좁았으니 `quality` 값을 낮춰서 불확실성을 더 넓게 표현하도록 하자. 그리고 유행의 진폭도 더 클 것 같으니 `amplitude_multiplier`를 2.2로 상향 조정해야겠다."
-   **가드레일 적용**: `agent_loop.py`는 LLM이 제안한 값들이 혹시라도 너무 비현실적일 경우를 대비해, `apply_hard_guards` 함수로 안전한 범위 내로 값을 강제 조정합니다.

#### **3단계: 시뮬레이션 실행 (핵심 예측 알고리즘)**

-   **`run_sim_wrapper.py`**: LLM이 최종적으로 확정한 하이퍼파라미터 세트를 받아 핵심 예측 엔진을 가동합니다.
-   **`scenario_engine.py`**: 수천 개의 미래 예측 경로를 생성합니다. (상세 로직은 Part 2에서 설명)
-   **`evt.py`**: 생성된 경로들 중, 비정상적으로 높은 피크 값을 가진 경로들을 통계적으로 보정하여 현실성을 높입니다.
-   **`run_sim_wrapper.py`**: 모든 경로가 생성되면, 각 미래 시점별로 값들을 정렬하여 중앙값(`q50`), 상위 95%(`q95`), 하위 5%(`q05`) 등을 계산합니다.

#### **4단계: 결과 검토 및 보고 (메트릭 계산 및 시각화)**

-   **`metrics.py`**: 생성된 예측값과 실제 값을 비교하여 `CRPS`, `coverage95` 등 다양한 성능 지표를 계산합니다.
-   **`agent_loop.py`**: 계산된 성능 지표를 `last_metrics`에 저장하여, 다음 주차의 예측을 위한 '피드백'으로 사용합니다.
-   **`rolling_agent_forecast.py`**: 모든 주차의 예측이 끝나면, 최종 결과를 종합하여 사용자가 보는 Plotly 기반의 인터랙티브 HTML 리포트를 생성하고 저장합니다.

---

## Part 2: 시스템의 심장부: 수학 및 로직 상세 분석

여기서는 3단계 시뮬레이션 과정의 내부 작동 원리를 수학적 공식과 함께 상세히 해부합니다.

### 2.1 `scenario_engine.py`: 과거 패턴으로 미래를 그리는 엔진

이 모듈의 핵심은 **과거의 '급증' 패턴을 재조합하여 미래를 예측**하는 것입니다.

#### **로직 1: 급등 에피소드(Growth Episode) 추출**

-   **목적**: 과거 데이터에서 의미 있는 '상승 패턴'을 학습 가능한 형태로 분리해냅니다.
-   **수학적 정의**: 주간 성장률 `\(g_t\)`가 임계값 `\(\tau\)`를 넘는 구간을 찾습니다.
    $$ g_t = \frac{y_t - y_{t-1}}{\max(1, y_{t-1})} \ge \tau $$
-   **작동 방식**:
    1.  `pct_threshold` 파라미터가 `\(\tau\)` 역할을 합니다.
    2.  `extract_growth_episodes` 함수는 이 조건을 만족하는 모든 과거의 급증 구간을 찾아냅니다.
    3.  단순히 값을 저장하는 것이 아니라, 각 에피소드의 시작점 값으로 모든 값을 나누어 **'형상(Shape)'**으로 정규화합니다. 이를 통해 유행의 절대적 크기와 무관하게 순수한 상승 '패턴' 자체를 학습합니다.

#### **로직 2: 조건부 경로 생성 (`generate_paths_conditional`)**

-   **목적**: 추출된 과거 에피소드들을 바탕으로, 현재 상황에 가장 적합한 미래 시나리오 경로들을 생성합니다.
-   **핵심 갱신 공식**: 한 주씩 미래로 나아가는 예측값 `\(x_h\)`는 다음 공식으로 계산됩니다.
    $$ x_h = x_{h-1} \cdot r^{\ast}_h \cdot c_h \cdot e^{\epsilon_h} $$
-   **공식 상세 해부**:
    *   `\(x_{h-1}\)`: **이전 값**. 바로 직전 주의 예측값입니다.
    *   `\(r^{\ast}_h\)`: **핵심 성장 동력 (Effective Growth Rate)**. 예측의 상승/하강을 결정하는 가장 중요한 부분입니다.
        1.  **유사도 기반 샘플링**: 먼저, '현재'와 가장 유사한 패턴을 보였던 과거 '급등 에피소드'를 더 높은 확률로 샘플링합니다.
        2.  **성장률 계산**: 샘플링된 에피소드의 '형상'에서 전주 대비 성장률(`ratios`)을 가져옵니다.
        3.  **진폭 조절**: 이 성장률에 `amplitude_multiplier`로 조절된 '진폭 스케일'을 곱하여 유행의 크기를 조절합니다. `amplitude_multiplier`는 LLM이 "이번 유행은 과거보다 더 클 것 같다"고 판단하면 높게 설정하는 핵심 파라미터입니다.
    *   `\(c_h\)`: **외부 요인 보정 (External Factor Correction)**.
        -   `news_signal` 파라미터가 이 역할을 합니다. LLM이 증거팩에서 "정부의 방역 정책 강화" 같은 신호를 읽었다면, 이 값을 조절하여 성장률을 억제하거나 증폭시킬 수 있습니다. `news_signal_weekly` 벡터가 제공되면, 매주 다른 보정값을 적용할 수도 있습니다.
    *   `\(e^{\epsilon_h}\)`: **현실적 불확실성 (Realistic Noise)**.
        -   예측은 항상 불확실성을 가집니다. 이 항은 `quality` 파라미터에 의해 제어되는 정규분포 노이즈입니다.
        -   LLM이 "데이터의 변동성이 크다"고 판단하여 `quality` 값을 낮추면, 노이즈의 표준편차가 커집니다. 이는 수천 개 시나리오 경로들의 분산을 넓혀, 최종 예측의 신뢰구간 밴드(q05-q95)를 넓히는 효과를 가져옵니다.

### 2.2 `evt.py`: '블랙 스완'에 대비하는 극단값 이론

-   **문제점**: `scenario_engine`은 과거에 나타났던 패턴에 기반하므로, **과거에 없었던 역대급 규모의 유행(블랙 스완)을 예측하기 어렵습니다.**
-   **해결책**: **극단값 이론(Extreme Value Theory, EVT)**을 도입합니다.
-   **로직**:
    1.  **`fit_pot` (Peak-Over-Threshold)**: 과거 데이터에서 상위 5% 또는 10%(`evt_u_quantile`)처럼 극단적으로 높았던 값들만 따로 추출합니다.
    2.  **GPD 피팅**: 이 극단값들의 분포에 **일반화 파레토 분포(Generalized Pareto Distribution, GPD)**라는 특수한 통계 모델을 피팅합니다. GPD는 극단적인 사건의 꼬리 분포를 모델링하는 데 특화되어 있습니다.
    3.  **`replace_tail_with_evt`**: `scenario_engine`이 생성한 경로들 중, GPD를 학습시킨 임계값을 초과하는 값이 나타나면, 그 값을 버리고 **GPD 모델에서 새로 샘플링한, 통계적으로 더 현실적인 극단값으로 교체**합니다.
-   **결과**: 이 과정을 통해, 시스템은 과거의 최대치를 뛰어넘는, 하지만 통계적으로는 발생 가능한 수준의 거대 유행을 시뮬레이션에 포함시킬 수 있게 되어, 예측의 안정성과 현실성이 크게 향상됩니다.

이 문서가 시스템의 전체적인 구조와 각 모듈의 역할을 깊이 이해하는 데 도움이 되기를 바랍니다.



